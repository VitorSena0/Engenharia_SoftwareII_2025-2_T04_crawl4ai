{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YM-DoCyvSgRU"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers accelerate gitpython pandas sentencepiece\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_nWfvhbsSm4D",
    "outputId": "6230d422-bc65-4e78-d75e-d279455bc5d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Reposit√≥rio clonado!\n",
      "üìÅ Evid√™ncias coletadas.\n"
     ]
    }
   ],
   "source": [
    "from git import Repo\n",
    "from pathlib import Path\n",
    "import subprocess, json, re, os, pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "# ==== CONFIGURA√á√ïES ====\n",
    "MODEL_ID = \"Qwen/Qwen2.5-Coder-0.5B-Instruct\"\n",
    "REPO_URL = \"https://github.com/unclecode/crawl4ai\"\n",
    "REPO_DIR = Path(\"/content/crawl4ai_repo\")\n",
    "OUT_DIR = Path(\"/content/resultados_qwen\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ==== 1. CLONAR REPOSIT√ìRIO ====\n",
    "if REPO_DIR.exists():\n",
    "    import shutil; shutil.rmtree(REPO_DIR)\n",
    "Repo.clone_from(REPO_URL, REPO_DIR)\n",
    "print(\"‚úÖ Reposit√≥rio clonado!\")\n",
    "\n",
    "# ==== 2. COLETAR EVID√äNCIAS ====\n",
    "def ler(p):\n",
    "    try: return Path(p).read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    except: return \"\"\n",
    "\n",
    "readme = ler(REPO_DIR/\"README.md\")\n",
    "tree = subprocess.check_output([\"bash\",\"-lc\",f\"cd {REPO_DIR} && find . -maxdepth 3 -type d | sort\"]).decode()\n",
    "\n",
    "evidencia = f\"\"\"\n",
    "README (trecho):\n",
    "{readme[:5000]}\n",
    "\n",
    "--- TREE ---\n",
    "{tree[:5000]}\n",
    "\"\"\"\n",
    "print(\"üìÅ Evid√™ncias coletadas.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 938,
     "referenced_widgets": [
      "ce0c1858d037488ca7971040a3518ea0",
      "aa9f253a151e4a70bfc7c702505e9438",
      "c82ad8c72eef4f198393baaf38c7350d",
      "33f343f9b449477a8ca9e56f23982f00",
      "4b249f76ce174a6e8a6280e2570d8a6c",
      "1756383b62864bdea38aa399601bead2",
      "d823aea069644fef85228634180bd04f",
      "d44f3c9bdeab40f8b43e0abe03841f70",
      "434879a785c34ff9b43e1c5888460d32",
      "4d973cd9f34a4b75a707f9a25f64fceb",
      "3a11ae13c16143b3841af568fc33fe67",
      "eaed11e6c8e04490ab7e926fcf33a719",
      "4c1926e7c6c24c6a8ef2db84fb0cbf48",
      "f053e028b57c46a38603d3b5a8ecb1c5",
      "42b04cebc2bf49509419dd2ce3e3d1f8",
      "1e566c0d51d74160b7b7f54720daa352",
      "d26c103e393b4dc4aa22eb60d649bf3d",
      "2c6140e881e4438d977737653ec78b05",
      "2266f18bb37e4a5c8e586b52ab3bc3ff",
      "0e281be7ff6248bd9fa034ccf8ab5b26",
      "d00ab930ea9b42b082ae74a400b2002e",
      "30378fde89564e19a8fac7a7ec4a6ced",
      "d2fb430bfc414f4da42c413ad04a7fca",
      "3050f44387164cf881ce8fe5c68c0f63",
      "6587c776fdc84aa9b3f4ca703fba0a71",
      "1b1205a7ea8244748be8fe5200e49183",
      "c2240765ddb14df4be1794360f6141ec",
      "a290686839cc4f198ff9d1f4cc8fff9e",
      "6c3ab03878fd4bf9b489b956495160ba",
      "a406cf90069a4da4a35696f23a9853af",
      "8fc4783574b243569a1327b8b5ba8c62",
      "3a4cbf1a1c164f1081bc9c697bfe1806",
      "aa35bfe3d9cb498dbad87e3f2eb3ef07",
      "6026d8ab901f418a844ec90150c71d88",
      "4f18395a5b9e403dabd01535447d65d0",
      "5062d6f8a57b491994f0fe2e01ea0b7a",
      "b31c1e66a0ad49e5bb2ab5f3315754ba",
      "5609f122ae314744bce47878e28344bd",
      "64a82dcd8d2b4ac9877b3e8f4a55ceeb",
      "66b968573e094914abb54159ea4d5f6e",
      "211d41830ac0496ab10707f7a524db94",
      "d6927916c3bc4ccfabcf6ee00e692984",
      "cc0d2d50120e473a9ee558d9a138a17c",
      "727d7fe571724e76af3152cc3e2b47fc",
      "6637440cfe1f453598db1d52c81b45bc",
      "b6081e8c4a45407bbf22d82cc42557da",
      "24daae3a0383497bb5f746d9d17d1643",
      "1f4250d7bcf14156a4996aaaa7892aa1",
      "ba1f9fe0ae644f7d823b0bd62420e578",
      "feffacacd5bc4554b9bf3e1ff541e031",
      "a003f425f19c44cfa10592b47dfe0317",
      "ca2797e2256e4213900243dd0246a65b",
      "0b8141de016f4000bdd5504f360fa9ab",
      "725a911bb816472596c28be8076d0e12",
      "ea2a99fe59424736871c727ff75873d7",
      "699e817f18224e41b4462437b776ed19",
      "7936f7a6cb1940139609eb54cb722879",
      "8ffd28228c954451b306c15d1134a3eb",
      "0152f507b0024871a0e21b61afffa426",
      "810a03ff3b59420e9ab8b9c4e3d120c9",
      "5f9b4578a12b4a0aaa35ebd08ad10e36",
      "7f38b8f60be54bf48e57ea16eeb799e3",
      "cec71fe4048347e0841023a2bd8d0097",
      "caa601a871a44f97baeb7b53bcfc4165",
      "afa2e63925cd4713968b20fda6cc93c7",
      "67d66518340148ff92b2a119c2e6d479",
      "458ac86afd7d45179806d9fa3796389d",
      "53f52036fddb436fa0a3cde9a008e889",
      "0768d5c9dff54e8a9b9b81a36e234947",
      "578682c8a788421da924e91d6173affc",
      "79003f8592ed48a3b4754559a8eb45d6",
      "ceeea0735d4843afa7251bdbc8078fc8",
      "19fa0df968d94e738bcb73394735e3a0",
      "153707a0dc5f4a17825a70d5fa50d6fb",
      "b11e62d2193343d0af776c6bfe14dc78",
      "2dd66b6ddfac4180a6a9accf23ba960d",
      "84c17cdeaebc452d91891354af1bd442"
     ]
    },
    "id": "cxkuTqufSo0_",
    "outputId": "b809f36b-35d0-4eb2-9544-58e915dd8442"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Carregando modelo Qwen (0.5B)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce0c1858d037488ca7971040a3518ea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaed11e6c8e04490ab7e926fcf33a719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2fb430bfc414f4da42c413ad04a7fca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6026d8ab901f418a844ec90150c71d88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6637440cfe1f453598db1d52c81b45bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/659 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "699e817f18224e41b4462437b776ed19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "458ac86afd7d45179806d9fa3796389d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/243 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GERA√á√ÉO BRUTA (primeiros 800 chars) ===\n",
      "{\n",
      "  \"patterns\": [\n",
      "    {\n",
      "      \"name\": \"Event-Driven\",\n",
      "      \"confidence\": 0.9,\n",
      "      \"evidence\": \"Crawl4AI is designed to be event-driven, allowing it to process web content in real-time.\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Plugin/Hook\",\n",
      "      \"confidence\": 0.8,\n",
      "      \"evidence\": \"Crawl4AI supports plugins and hooks, enabling developers to extend its functionality.\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Layered/MVC\",\n",
      "      \"confidence\": 0.7,\n",
      "      \"evidence\": \"Crawl4AI uses a layered MVC architecture, allowing it to manage different parts of the application.\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Microservices\",\n",
      "      \"confidence\": 0.6,\n",
      "      \"evidence\": \"Crawl4AI is built on microservices architecture, enabling it to handle complex applications.\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Cloud-Native/Containerized\",\n",
      "      \"confi\n",
      "‚úÖ Salvos:\n",
      " - /content/resultados_qwen/patterns_qwen.json\n",
      " - /content/resultados_qwen/patterns_qwen_summary.csv\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import json, re, ast\n",
    "\n",
    "print(\"üöÄ Carregando modelo Qwen (0.5B)...\")\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "mdl = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID, device_map=\"auto\", torch_dtype=\"auto\", trust_remote_code=True\n",
    ")\n",
    "gen = pipeline(\"text-generation\", model=mdl, tokenizer=tok)\n",
    "\n",
    "# Mensagens em formato chat: isso ajuda o Qwen a obedecer \"somente JSON\"\n",
    "messages = [\n",
    "  {\"role\": \"system\",\n",
    "   \"content\": (\n",
    "     \"Voc√™ √© um analista de arquitetura. Responda ESTRITAMENTE em JSON, \"\n",
    "     \"sem explica√ß√µes, sem crases, sem texto extra. \"\n",
    "     \"Formato obrigat√≥rio:\\n\"\n",
    "     \"{\\n\"\n",
    "     '  \"patterns\": [\\n'\n",
    "     '    {\"name\": \"<Padr√£o>\", \"confidence\": 0.0, \"evidence\": \"<frase>\"}\\n'\n",
    "     \"  ],\\n\"\n",
    "     '  \"notes\": \"<observa√ß√µes curtas>\"\\n'\n",
    "     \"}\"\n",
    "   )},\n",
    "  {\"role\": \"user\",\n",
    "   \"content\": (\n",
    "     \"Analise as evid√™ncias e identifique PADR√ïES ARQUITETURAIS. \"\n",
    "     \"Use nomes can√¥nicos como: Event-Driven, Plugin/Hook, Layered/MVC, \"\n",
    "     \"Microservices, Cloud-Native/Containerized, Pipeline/Dataflow, Client-Server/API. \"\n",
    "     \"M√ÅXIMO 5 padr√µes.\\n\\n\"\n",
    "     \"EVID√äNCIAS:\\n\" + evidencia\n",
    "   )}\n",
    "]\n",
    "\n",
    "prompt_chat = tok.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "# Gera√ß√£o determin√≠stica e curta (evita ‚Äúconversa‚Äù extra)\n",
    "out = gen(\n",
    "    prompt_chat,\n",
    "    max_new_tokens=380,\n",
    "    do_sample=False,\n",
    "    temperature=0.0,\n",
    "    return_full_text=False,              # <- importante p/ n√£o repetir o prompt\n",
    "    eos_token_id=tok.eos_token_id,\n",
    "    pad_token_id=tok.eos_token_id\n",
    ")[0][\"generated_text\"]\n",
    "\n",
    "print(\"=== GERA√á√ÉO BRUTA (primeiros 800 chars) ===\")\n",
    "print(out[:800])\n",
    "\n",
    "# ---- Parse robusto ----\n",
    "def extrair_bloco_json(texto):\n",
    "    # pega do primeiro { ao √∫ltimo }\n",
    "    ini = texto.find(\"{\")\n",
    "    fim = texto.rfind(\"}\")\n",
    "    return texto[ini:fim+1] if ini != -1 and fim != -1 and fim > ini else texto\n",
    "\n",
    "raw = extrair_bloco_json(out).strip()\n",
    "\n",
    "def tentar_parse(raw_text):\n",
    "    # 1) JSON direto\n",
    "    try:\n",
    "        return json.loads(raw_text)\n",
    "    except:\n",
    "        pass\n",
    "    # 2) Troca aspas simples por duplas\n",
    "    try:\n",
    "        return json.loads(raw_text.replace(\"'\", '\"'))\n",
    "    except:\n",
    "        pass\n",
    "    # 3) literal_eval (aceita dict Python)\n",
    "    try:\n",
    "        return ast.literal_eval(raw_text)\n",
    "    except:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "data = tentar_parse(raw)\n",
    "\n",
    "# fallback m√≠nimo: se ainda falhar, gera JSON com heur√≠stica simples pelas evid√™ncias\n",
    "if not data or not isinstance(data, dict) or \"patterns\" not in data:\n",
    "    pats = []\n",
    "    ev_txt = evidencia.lower()\n",
    "    if \"webhook\" in ev_txt or \"queue\" in ev_txt or \"event\" in ev_txt:\n",
    "        pats.append({\"name\":\"Event-Driven\",\"confidence\":0.75,\"evidence\":\"Men√ß√µes a webhooks/filas/eventos no README/estrutura.\"})\n",
    "    if \"hook\" in ev_txt or \"plugin\" in ev_txt:\n",
    "        pats.append({\"name\":\"Plugin/Hook\",\"confidence\":0.72,\"evidence\":\"Sistema de hooks/plugins citado nas evid√™ncias.\"})\n",
    "    if \"docker\" in ev_txt or \"compose\" in ev_txt:\n",
    "        pats.append({\"name\":\"Cloud-Native/Containerized\",\"confidence\":0.70,\"evidence\":\"Arquivos Docker/compose indicam cont√™ineres.\"})\n",
    "    data = {\"patterns\": pats, \"notes\": \"Parse do modelo falhou; heur√≠stica aplicada sobre as evid√™ncias.\"}\n",
    "\n",
    "# salva\n",
    "json_path = OUT_DIR/\"patterns_qwen.json\"\n",
    "with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# resumo CSV\n",
    "import pandas as pd\n",
    "rows = [{\"pattern\": p.get(\"name\",\"\"), \"confidence\": p.get(\"confidence\",\"\"), \"evidence\": p.get(\"evidence\",\"\")} for p in data.get(\"patterns\",[])]\n",
    "pd.DataFrame(rows).to_csv(OUT_DIR/\"patterns_qwen_summary.csv\", index=False)\n",
    "\n",
    "print(\"‚úÖ Salvos:\")\n",
    "print(\" -\", json_path)\n",
    "print(\" -\", OUT_DIR/\"patterns_qwen_summary.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U2AfG3txwdmi",
    "outputId": "f7917ca5-00da-4dce-e881-7632a79e3b8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"patterns\": [\n",
      "    {\n",
      "      \"name\": \"Event-Driven\",\n",
      "      \"confidence\": 0.9,\n",
      "      \"evidence\": \"Crawl4AI is designed to be event-driven, allowing it to process web content in real-time.\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Plugin/Hook\",\n",
      "      \"confidence\": 0.8,\n",
      "      \"evidence\": \"Crawl4AI supports plugins and hooks, enabling developers to extend its functionality.\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Layered/MVC\",\n",
      "      \"confidence\": 0.7,\n",
      "      \"evidence\": \"Crawl4AI uses a layered MVC architecture, allowing it to manage different parts of the application.\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Microservices\",\n",
      "      \"confidence\": 0.6,\n",
      "      \"evidence\": \"Crawl4AI is built on microservices architecture, enabling it to handle complex applications.\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Cloud-Native/Containerized\",\n",
      "      \"confidence\": 0.5,\n",
      "      \"evidence\": \"Crawl4AI is designed to run on cloud-native environments, such as Kubernetes and Docker.\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Pipeline/Dataflow\",\n",
      "      \"confidence\": 0.4,\n",
      "      \"evidence\": \"Crawl4AI supports pipeline and dataflow architectures, enabling developers to automate tasks.\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Client-Server/API\",\n",
      "      \"confidence\": 0.3,\n",
      "      \"evidence\": \n",
      "pattern,confidence,evidence\n",
      "Event-Driven,0.9,\"Crawl4AI is designed to be event-driven, allowing it to process web content in real-time.\"\n",
      "Plugin/Hook,0.8,\"Crawl4AI supports plugins and hooks, enabling developers to extend its functionality.\"\n",
      "Layered/MVC,0.7,\"Crawl4AI uses a layered MVC architecture, allowing it to manage different parts of the application.\"\n",
      "Microservices,0.6,\"Crawl4AI is built on m\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "print(Path(\"/content/resultados_qwen/patterns_qwen.json\").read_text()[:1200])\n",
    "print(Path(\"/content/resultados_qwen/patterns_qwen_summary.csv\").read_text()[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "TjMiDrilztkW",
    "outputId": "5aa096e4-b946-462c-8816-8455f94c489b"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_3719ccbd-3e86-4d14-93de-4ddc54fe8575\", \"patterns_qwen.json\", 1476)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_7de689ab-ee91-4b06-8b49-521bf6d84954\", \"patterns_qwen_summary.csv\", 823)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.download(\"/content/resultados_qwen/patterns_qwen.json\")\n",
    "files.download(\"/content/resultados_qwen/patterns_qwen_summary.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ag0vTS-L84Pq",
    "outputId": "ac9b6dd1-c219-4637-c976-513d5d0523e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Verificando arquivos do resultado...\n",
      "\n",
      "‚úÖ Arquivos encontrados:\n",
      " - /content/resultados_qwen/patterns_qwen.json\n",
      " - /content/resultados_qwen/patterns_qwen_summary.csv\n",
      "üì¶ Tamanho JSON: 1476 bytes\n",
      "üì¶ Tamanho CSV:  823 bytes\n",
      "\n",
      "üìä Padr√µes detectados: 7\n",
      " - Event-Driven (confian√ßa: 0.9)\n",
      " - Plugin/Hook (confian√ßa: 0.8)\n",
      " - Layered/MVC (confian√ßa: 0.7)\n",
      " - Microservices (confian√ßa: 0.6)\n",
      " - Cloud-Native/Containerized (confian√ßa: 0.5)\n",
      " - Pipeline/Dataflow (confian√ßa: 0.4)\n",
      " - Client-Server/API (confian√ßa: 0.3)\n",
      "\n",
      "üß† Observa√ß√µes: Crawl4AI is a versatile and powerful web crawler and scraper that can be used for a wide range of tasks, including web scraping, data extraction, and automation.\n",
      "\n",
      "‚úÖ Resultado gerado diretamente pelo modelo (sem fallback).\n",
      "\n",
      "üìÑ Pr√©via do arquivo CSV:\n",
      "pattern,confidence,evidence\n",
      "Event-Driven,0.9,\"Crawl4AI is designed to be event-driven, allowing it to process web content in real-time.\"\n",
      "Plugin/Hook,0.8,\"Crawl4AI supports plugins and hooks, enabling developers to extend its functionality.\"\n",
      "Layered/MVC,0.7,\"Crawl4AI uses a layered MVC architecture, \n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json, re\n",
    "\n",
    "# Caminhos dos arquivos salvos\n",
    "base = Path(\"/content/resultados_qwen\")\n",
    "json_file = base / \"patterns_qwen.json\"\n",
    "csv_file  = base / \"patterns_qwen_summary.csv\"\n",
    "\n",
    "print(\"üìÅ Verificando arquivos do resultado...\\n\")\n",
    "\n",
    "# 1Ô∏è‚É£ Checar tamanho e exist√™ncia\n",
    "if not json_file.exists() or not csv_file.exists():\n",
    "    print(\"‚ùå Arquivos n√£o encontrados. Execute novamente a c√©lula do modelo.\")\n",
    "else:\n",
    "    print(f\"‚úÖ Arquivos encontrados:\\n - {json_file}\\n - {csv_file}\")\n",
    "    print(f\"üì¶ Tamanho JSON: {json_file.stat().st_size} bytes\")\n",
    "    print(f\"üì¶ Tamanho CSV:  {csv_file.stat().st_size} bytes\")\n",
    "\n",
    "# 2Ô∏è‚É£ Tentar ler o JSON\n",
    "try:\n",
    "    data = json.loads(json_file.read_text(encoding=\"utf-8\"))\n",
    "    pats = data.get(\"patterns\", [])\n",
    "    print(f\"\\nüìä Padr√µes detectados: {len(pats)}\")\n",
    "    for p in pats:\n",
    "        print(f\" - {p['name']} (confian√ßa: {p['confidence']})\")\n",
    "    print(\"\\nüß† Observa√ß√µes:\", data.get(\"notes\", \"\"))\n",
    "except Exception as e:\n",
    "    print(\"‚ö†Ô∏è JSON inv√°lido ou corrompido:\", e)\n",
    "\n",
    "# 3Ô∏è‚É£ Detectar se foi fallback (heur√≠stico)\n",
    "raw = json_file.read_text(encoding=\"utf-8\").lower()\n",
    "if \"heur√≠stica aplicada\" in raw or \"fallback\" in raw:\n",
    "    print(\"\\n‚ö†Ô∏è Aviso: Resultado veio do PARSE HEUR√çSTICO (modelo n√£o retornou JSON completo).\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Resultado gerado diretamente pelo modelo (sem fallback).\")\n",
    "\n",
    "# 4Ô∏è‚É£ Visual r√°pido do CSV\n",
    "print(\"\\nüìÑ Pr√©via do arquivo CSV:\")\n",
    "print(Path(csv_file).read_text(encoding=\"utf-8\")[:300])\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
