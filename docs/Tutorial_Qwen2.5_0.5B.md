# ğŸ“˜ Tutorial Completo â€” AnÃ¡lise Arquitetural com Qwen/Qwen2.5-Coder-0.5B-Instruct

Este tutorial descreve detalhadamente como executar a anÃ¡lise arquitetural do projeto **Crawl4AI** utilizando o modelo **Qwen/Qwen2.5-Coder-0.5B-Instruct** no Google Colab.  
O processo engloba coleta de evidÃªncias, execuÃ§Ã£o do modelo, parse das respostas, fallback heurÃ­stico e uma etapa experimental de anÃ¡lise do cÃ³digo-fonte via chunking.

---

## ğŸ”§ 1. PrÃ©-requisitos

Antes de executar este tutorial, vocÃª precisa:

- Conta no **Hugging Face**
- Um **Hugging Face Inference Token**
- Conta no **Google Colab**
- Familiaridade bÃ¡sica com Python e notebooks

O modelo utilizado Ã©:

```
Qwen/Qwen2.5-Coder-0.5B-Instruct
```

Ele roda integralmente em **CPU**, ideal para ambientes sem GPU.

---

## ğŸ“¥ 2. Clonando o repositÃ³rio do Crawl4AI

```python
from git import Repo
from pathlib import Path
import subprocess

REPO_URL = "https://github.com/unclecode/crawl4ai"
REPO_DIR = Path("/content/crawl4ai_repo")

if REPO_DIR.exists():
    import shutil
    shutil.rmtree(REPO_DIR)

Repo.clone_from(REPO_URL, REPO_DIR)
print("RepositÃ³rio clonado!")
```

---

## ğŸ“‘ 3. Coleta automÃ¡tica de evidÃªncias textuais

```python
def ler(p):
    try:
        return Path(p).read_text(encoding="utf-8", errors="ignore")
    except:
        return ""

readme = ler(REPO_DIR/"README.md")

tree = subprocess.check_output(
    ["bash","-lc", f"cd {REPO_DIR} && find . -maxdepth 3 -type d | sort"]
).decode()

evidencia = f"""
README (trecho):
{readme[:5000]}

--- TREE ---
{tree[:5000]}
"""
print("EvidÃªncias coletadas.")
```

---

## ğŸ¤– 4. Carregando o modelo Qwen 0.5B no Colab

```python
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline

MODEL_ID = "Qwen/Qwen2.5-Coder-0.5B-Instruct"

tok = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)
mdl = AutoModelForCausalLM.from_pretrained(
    MODEL_ID, device_map="auto", torch_dtype="auto", trust_remote_code=True
)

gen = pipeline("text-generation", model=mdl, tokenizer=tok)
print("Modelo carregado!")
```

---

## ğŸ’¬ 5. Construindo o prompt de anÃ¡lise arquitetural

```python
messages = [
  {"role": "system",
   "content":
     "VocÃª Ã© um analista de arquitetura. Responda ESTRITAMENTE em JSON..."
  },
  {"role": "user",
   "content":
     "Analise as evidÃªncias e identifique PADRÃ•ES ARQUITETURAIS..."
     "\nEVIDÃŠNCIAS:\n" + evidencia
  }
]

prompt_chat = tok.apply_chat_template(
    messages, tokenize=False, add_generation_prompt=True
)
```

---

## ğŸ§  6. ExecuÃ§Ã£o do modelo

```python
out = gen(
    prompt_chat,
    max_new_tokens=380,
    do_sample=False,
    temperature=0.0,
    return_full_text=False
)[0]["generated_text"]

print("GeraÃ§Ã£o bruta:")
print(out[:800])
```

---

## ğŸ“¦ 7. Parse do JSON + fallback heurÃ­stico

```python
def extrair_bloco_json(texto):
    ini = texto.find("{")
    fim = texto.rfind("}")
    return texto[ini:fim+1] if ini != -1 and fim != -1 else texto
```

Fallback usado:

```python
if "webhook" in ev_txt:
    pats.append({"name":"Event-Driven","confidence":0.75,"evidence":"MenÃ§Ãµes a eventos/webhooks."})
```

---

## ğŸ’¾ 8. Salvando os arquivos de saÃ­da

Os arquivos gerados:

```
patterns_qwen.json
patterns_qwen_summary.csv
```

---

## ğŸ§© 9. Fase experimental â€” anÃ¡lise de cÃ³digo-fonte (chunking)

O modelo nÃ£o conseguiu interpretar corretamente os arquivos `.py` devido Ã s limitaÃ§Ãµes de tamanho.  
Mesmo assim, o mÃ©todo de chunking funcionou tecnicamente.

---

## ğŸ“Š 10. PadrÃµes identificados

| PadrÃ£o Arquitetural      | ConfianÃ§a | EvidÃªncia |
|-------------------------|-----------|-----------|
| Event-Driven            | 0.75â€“0.90 | Webhooks, eventos |
| Plugin/Hook             | 0.72â€“0.80 | Sistema de extensÃµes |
| Cloud-Native            | ~0.70     | Docker/Compose |

---

## ğŸ¯ 11. ConclusÃ£o

O modelo Qwen 0.5B funciona bem para anÃ¡lises de documentaÃ§Ã£o,  
mas Ã© insuficiente para anÃ¡lise aprofundada de cÃ³digo-fonte.

---

## ğŸ‘¤ 12. ContribuiÃ§Ã£o Individual

- ExecuÃ§Ã£o da anÃ¡lise arquitetural  
- ImplementaÃ§Ã£o do fallback  
- AnÃ¡lise experimental do cÃ³digo  
- OrganizaÃ§Ã£o da metodologia e resultados  

---
